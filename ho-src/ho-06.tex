\documentclass{tufte-handout}

\usepackage{amssymb,amsmath}
% \usepackage{mathspec}
\usepackage{graphicx,grffile}
\usepackage{longtable}
\usepackage{booktabs}

\newtheorem{mydef}{Definition}[section]
\newtheorem{thm}{Theorem}[section]
\setcounter{section}{4}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand{\Lim}[1]{\raisebox{0.5ex}{\scalebox{0.8}{$\displaystyle \lim_{#1}\;$}}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\V}{\text{Var}}
\newcommand{\iid}{\stackrel{iid}{\sim}}
\newcommand{\cblack}{\color{Black}}
\newcommand{\cblue}{\color{MidnightBlue}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

\begin{document}

\justify

{\LARGE Handout 06: Hypothesis Testing}

\vspace*{18pt}

\noindent
An hypothesis test is a way of establishing whether a random sample
offers support for a particular conclusion about the population 
distribution $\mathcal{G}$. The mechanics of hypothesis testing are
similar to those of confidence intervals, but the interpretation and
terminology differs. For an hypothesis test, we start with a
\textbf{null hypothesis} $H_0$ and see if the data support rejecting
this baseline assumption in favor of an \textbf{alternative hypothesis}
$H_A$. 

In its formal specification, to do an hypothesis test we first select
a \textbf{significance level} $(1-\alpha)$ and construct an event $R$,
called a \textbf{rejection region}, such that $\Prob[R | H_0] \leq \alpha$.
If we then observe some data and $R$ occurs, we \textbf{reject} the
null hypothesis in favor of the alternative. Otherwise, we \textbf{retain}
(or fail to reject) the null hypothesis. The goal is to create a rejection
region that has a much higher probability of occuring under the alternative
hypothesis than it does under the null.

The standard approach to creating a rejection region is to start with a
pivot, plug in the parameters of the null distribution, and then form a
\textbf{test statistic} with a known distribution under $H_0$. Then, we
can create something similar to a confidence interval around the test
statistic and use the complement of that as the rejection region. Let's
see an example! Assume that you have a random sample from a normal 
distribution with unknown mean and unknown variance. We will do an 
hypothesis test with $H_0: \mu = 1$ and $H_A: \mu \neq 1$. We form a
test statistic $T$ using the pivot quantity that we saw last week, but
with $\mu_X$ replaced with the null hypothesis value of $1$:\footnote{
  I have reversed the numerator from the previous notes to follow
  the standard convention that a positive $T$ corresponds to a mean
  higher than the null hypothesis. Due to the symmetry of the
  t-distribution, $T$ still has the same t-distribution either way.
}
\begin{align*}
T &= \frac{\bar{X} - 1}{\sqrt{S_X^2 / n}} 
\end{align*}
Under $H_0$, $T \sim t(n-1)$. A rejection region $R$ can be given by
the following event:
\begin{align*}
R &= \left\{ -t_{\alpha/2} \leq T \leq t_{\alpha/2} \right\}^{c}.
\end{align*}
Due to the way it is defined, this will have the desired property that
$\Prob[R|H_0] \leq \alpha$. A common shorthand for the rejection
region is to call the quantity $t_{\alpha/2}$ a \textbf{critical value},
and then simply reject the null hypothesis if the (absolute value) of the
test statistic exceeds the critical value. Hypothesis test procedures
are oftene named based on the distribution of the test statistic.\footnote{
  This is not an ideal convention because many different tests can have
  the same test statistic distribution. The naming convention causes constant
  confusion. We can talk more about ways to mitigate these issues in your own
  work.
}
Here, we have derived what is called the \textbf{one-sample T-test}. 

\vspace*{20pt}

\noindent
There is another related way of doing hypothesis testing that, at least
initially, forgoes the language about rejecting or retaining the null 
hypothesis. Instead of having a fixed critical value, we could ask the
question: what is the smallest value of $\alpha$ such that corresponding
test statistic would be equal to (or greater than) the critical value? 
For example, if we observe a positive value of $t$ from a T-test, we could
define $p$ such that: 
\begin{align*}
\Prob[t \leq T] &= p. 
\end{align*}
This quantity is called a \textbf{p-value}. A p-value is usually the 
form that statistical software will report the results of an hypothesis
test and is increasingly the way that results are communicated through.
Note that we can recover the concept of statistical significance by 
simply checking the p-value is less than the significant level. If it
is, we have a statistically significant result and would reject the null
hypothesis in favor of the alternative hypothesis.

One can always use the p-value as a number that we use to compare to
our specific values of $\alpha$ and then determine whether to reject
or retain $H_0$. There is a lot of discussion in statistics about how
the p-value itself should be interpreted beyond this, if at all. 

\end{document}

